{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7389629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from markitdown import MarkItDown\n",
    "import os \n",
    "from PyPDF2 import PdfFileReader, PdfFileWriter \n",
    "from pypdf import PdfReader, PdfWriter\n",
    "import shlex\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6088ce62",
   "metadata": {},
   "source": [
    "Garder la dernière page du PDF : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0b6bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_last_page(input_path, output_path):\n",
    "    # On lit le PDF original\n",
    "    reader = PdfReader(input_path)\n",
    "    writer = PdfWriter()\n",
    "\n",
    "    # On garde la dernière page\n",
    "    last_page = reader.pages[-1]\n",
    "    writer.add_page(last_page)\n",
    "\n",
    "    # On la met dans un nouveau PDF\n",
    "    with open(output_path, \"wb\") as output_file:\n",
    "        writer.write(output_file)\n",
    "\n",
    "    print(f\"Last page saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cffdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on vérifie que le fichier n'est pas html (c'est le cas quand c'est mal extrait)\n",
    "\n",
    "def is_html(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        header = f.read(1024).lower()\n",
    "        return b\"<html\" in header or b\"<!doctype html\" in header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0fa626",
   "metadata": {},
   "source": [
    "Conversion PDF en Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56b5bdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\A'\n",
      "C:\\Users\\lisef\\AppData\\Local\\Temp\\ipykernel_16024\\700113543.py:2: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  result = markitdown.convert('pdfs\\ACSA%201_2.pdf')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACSA 1\n",
      "\n",
      "CMA CGM weekly fixed-day service connecting Far East and West Coast South America\n",
      "\n",
      "Busan\n",
      "\n",
      "Yokohama\n",
      "\n",
      "Busan\n",
      "\n",
      "Yokohama\n",
      "\n",
      "Shanghai\n",
      "Ningbo\n",
      "\n",
      "Shanghai\n",
      "Ningbo\n",
      "\n",
      "Keelung\n",
      "\n",
      "Chiwan\n",
      "\n",
      "Hong Kong\n",
      "\n",
      "Manzanillo\n",
      "\n",
      "Chancay\n",
      "Callao\n",
      "\n",
      "Arica\n",
      "\n",
      "Iquique\n",
      "\n",
      "INCA\n",
      "\n",
      "Chancay\n",
      "Callao\n",
      "\n",
      "San Antonio\n",
      "Lirquen\n",
      "\n",
      "INCA2\n",
      "\n",
      "Balboa\n",
      "\n",
      "Posorja\n",
      "\n",
      "Chancay\n",
      "Callao\n",
      "Callao\n",
      "\n",
      "San Antonio\n",
      "\n",
      "CMA CGM Strengths\n",
      "\n",
      "•  Direct and unique product offering fastest transit time between Far East & West Coast South America (WCSA)\n",
      "•  Direct call to San Antonio, offering the most competitive transit time on the market\n",
      "•  Seamless connection with CMA CGM direct fixed-day weekly INCA services (to connect Arica/Iquique/Lirquen)\n",
      "•  Designed for perishable and fresh fruit in reefer containers from West Coast South America to the Far East\n",
      "\n",
      "\fACSA 1\n",
      "\n",
      "CMA CGM weekly fixed-day service connecting Far East and West Coast South America\n",
      "\n",
      "TRANSIT TIMES*\n",
      "\n",
      "EASTBOUND\n",
      "\n",
      "SAN ANTONIO\n",
      "\n",
      "CHANCAY\n",
      "\n",
      "CALLAO\n",
      "\n",
      "POSORJA\n",
      "\n",
      "YOKOHAMA\n",
      "\n",
      "BUSAN\n",
      "\n",
      "SHANGHAI\n",
      "\n",
      "NINGBO\n",
      "\n",
      "41\n",
      "\n",
      "36\n",
      "\n",
      "32\n",
      "\n",
      "29\n",
      "\n",
      "WESTBOUND\n",
      "\n",
      "49\n",
      "\n",
      "45\n",
      "\n",
      "40\n",
      "\n",
      "38\n",
      "\n",
      "51\n",
      "\n",
      "46\n",
      "\n",
      "42\n",
      "\n",
      "39\n",
      "\n",
      "55\n",
      "\n",
      "50\n",
      "\n",
      "46\n",
      "\n",
      "44\n",
      "\n",
      "YOKOHAMA\n",
      "\n",
      "BUSAN\n",
      "\n",
      "SHANGHAI\n",
      "\n",
      "NINGBO\n",
      "\n",
      "SAN ANTONIO\n",
      "\n",
      "CHANCAY\n",
      "\n",
      "CALLAO\n",
      "\n",
      "POSORJA\n",
      "\n",
      "33\n",
      "\n",
      "MIAMI\n",
      "\n",
      "27\n",
      "\n",
      "24\n",
      "\n",
      "20\n",
      "\n",
      "37\n",
      "\n",
      "31\n",
      "\n",
      "29\n",
      "\n",
      "24\n",
      "\n",
      "41\n",
      "\n",
      "35\n",
      "\n",
      "33\n",
      "\n",
      "28\n",
      "\n",
      "44\n",
      "\n",
      "38\n",
      "\n",
      "35\n",
      "\n",
      "31\n",
      "\n",
      "*Non contractual information\n",
      "\n",
      "CONTACTS\n",
      "\n",
      "Head Office, Marseille\n",
      "\n",
      "Guillaume DEFAY - Deputy Vice President\n",
      "Tel: + 33 4 88 91 61 95\n",
      "Mail: ho.gdefay@cma-cgm.com\n",
      "\n",
      "Cédric MOUTON - Line Manager\n",
      "Tel: + 33 4 88 91 82 25\n",
      "Mail: ho.cmouton@cma-cgm.com\n",
      "\n",
      "Regional Office Singapore\n",
      "\n",
      "Annabelle MONIER - Head of LATAM\n",
      "Tel: + (65) 83 39 98 03\n",
      "Mail: sgp.amonier@cma-cgm.com\n",
      "\n",
      "Regional Office, Miami\n",
      "\n",
      "Adriana JIMENEZ - Trade Senior Manager\n",
      "Tel: + 1 (305) 398-9837\n",
      "Mail: usa.ajimenez@cma-cgm.com\n",
      "\n",
      "Maria ARCE - Trade Director - Reefer LATAM\n",
      "Tel: + 1 (305) 398-3722\n",
      "Mail: usa.marce@usa.cma-cgm.com\n",
      "\n",
      "m\n",
      "o\n",
      "c\n",
      ".\n",
      "m\n",
      "g\n",
      "c\n",
      "-\n",
      "a\n",
      "m\n",
      "c\n",
      ".\n",
      "w\n",
      "w\n",
      "w\n",
      "\n",
      "April 2025\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "markitdown = MarkItDown()\n",
    "result = markitdown.convert('pdfs\\ACSA%201_2.pdf')\n",
    "print(result.text_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f21835",
   "metadata": {},
   "source": [
    "LLM - PDF : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e61ec8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\W'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\W'\n",
      "C:\\Users\\lisef\\AppData\\Local\\Temp\\ipykernel_16024\\2788557382.py:3: SyntaxWarning: invalid escape sequence '\\W'\n",
      "  input_file_1 = \"pdfs\\WAX_0.pdf\"\n"
     ]
    }
   ],
   "source": [
    "# Extraction des tableaux à l'aide de la plateforme de LLM\n",
    "\n",
    "input_file_1 = \"pdfs\\WAX_0.pdf\"\n",
    "\n",
    "with open(input_file_1, \"r\", encoding=\"utf-8\") as f1:\n",
    "    pdf_content = PdfReader('C:\\\\Users\\\\lisef\\\\projet-buyco\\\\Buyco\\\\pdfs\\\\WAX_0.pdf').pages[0]\n",
    "\n",
    "input_file_2 = \"WAX_0.md\"\n",
    "\n",
    "with open(input_file_2, \"r\", encoding=\"utf-8\") as f2:\n",
    "    markdown_content = f2.read()\n",
    "\n",
    "\n",
    "prompt_LLM_fra = f\"\"\"Voici le contenu d'un fichier PDF pour comprendre la forme et d'un fichier Markdown. \n",
    "Extrait uniquement les tableaux de temps de transit** (Transit Times), et rends-les sous forme de \n",
    "tableaux lisibles .csv Ne commente pas, ne reformule pas.\n",
    "PDF : {pdf_content}, Markdown : {markdown_content}\"\"\"\n",
    "\n",
    "prompt_LLM = f\"\"\"This is a PDF file to understand the way it is and a Markdown file. Extract only \n",
    "Transit Times' tables and give them back to me on a readable .csv format. Don't comment and don't repharse.\n",
    "PDF : {pdf_content}, Markdown : {markdown_content}\"\"\"\n",
    "\n",
    "safe_prompt_LLM = shlex.quote(prompt_LLM)\n",
    "\n",
    "output_file = \"WAX_0.txt\"\n",
    "\n",
    "\n",
    "# Méthode requests\n",
    "\n",
    "url = \"http://ollama-sam.inria.fr/api/generate\"\n",
    "data = {'model': 'mistral:7b', 'prompt': safe_prompt_LLM}\n",
    "auth = ('Bob', 'hiccup')  # HTTP Basic Auth\n",
    "\n",
    "response = requests.post(url, json=data, auth=auth)\n",
    "\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as out_file:\n",
    "    out_file.write(response.text)\n",
    "\n",
    "\n",
    "\n",
    "# Extraitre les fichiers .csv du fichier text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3d9633",
   "metadata": {},
   "source": [
    "Boucler sur tous les fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed420c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:19: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:19: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<string>:19: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:19: SyntaxWarning: invalid escape sequence '\\{'\n",
      "C:\\Users\\lisef\\AppData\\Local\\Temp\\ipykernel_16024\\700528354.py:19: SyntaxWarning: invalid escape sequence '\\{'\n",
      "  input_file = f\"pdfs_extraits\\{nom_fichier}.pdf\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1: 3 tables détectées\n",
      "Table 1 saved in extract_ABIDJAN%20REEFER%20TUNA%20EXPORT_table_1.csv\n",
      "Table 2 saved in extract_ABIDJAN%20REEFER%20TUNA%20EXPORT_table_2.csv\n",
      "Page 1: 6 tables détectées\n",
      "Table 1 saved in extract_ACSA%201_2_table_1.csv\n",
      "Table 2 saved in extract_ACSA%201_2_table_2.csv\n",
      "Page 1: 6 tables détectées\n",
      "Table 1 saved in extract_ACSA%202_2_table_1.csv\n",
      "Table 2 saved in extract_ACSA%202_2_table_2.csv\n",
      "Page 1: 6 tables détectées\n",
      "Table 1 saved in extract_ACSA%203_0_table_1.csv\n",
      "Table 2 saved in extract_ACSA%203_0_table_2.csv\n",
      "Page 1: 2 tables détectées\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisef\\AppData\\Local\\Temp\\ipykernel_16024\\700528354.py:19: SyntaxWarning: invalid escape sequence '\\{'\n",
      "  input_file = f\"pdfs_extraits\\{nom_fichier}.pdf\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Bloc markdown ``` non trouvé dans le fichier de réponse",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 112\u001b[0m\n\u001b[0;32m    110\u001b[0m match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```(.*?)```\u001b[39m\u001b[38;5;124m\"\u001b[39m, content, re\u001b[38;5;241m.\u001b[39mDOTALL)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m match:\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBloc markdown ``` non trouvé dans le fichier de réponse\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    114\u001b[0m tables_text \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m    116\u001b[0m lines \u001b[38;5;241m=\u001b[39m [line\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m tables_text\u001b[38;5;241m.\u001b[39msplitlines() \u001b[38;5;28;01mif\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstrip()]\n",
      "\u001b[1;31mValueError\u001b[0m: Bloc markdown ``` non trouvé dans le fichier de réponse"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import shlex\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "from pypdf import PdfReader, PdfWriter\n",
    "\n",
    "path = 'C:\\\\Users\\\\lisef\\\\projet-buyco\\\\Buyco\\\\pdfs_extraits' # chemin d'accès des pdfs\n",
    "subdirectories = os.listdir(path)\n",
    "\n",
    "for fichier in subdirectories:\n",
    "    if not is_html(f'C:\\\\Users\\\\lisef\\\\projet-buyco\\\\Buyco\\\\pdfs_extraits\\\\{fichier}'):\n",
    "        vrai_fichier = re.search('[^.]*',f'{fichier}')\n",
    "        nom_fichier = vrai_fichier.group(0) # on ne garde que le nom sans l'extension\n",
    "\n",
    "        # Conversion pdf en Markdown\n",
    "\n",
    "    input_file = f\"pdfs_extraits\\{nom_fichier}.pdf\" \n",
    "    output_file = f\"{nom_fichier}.md\" \n",
    "\n",
    "    def pdf_tables_to_markdown(pdf_path, output_md):\n",
    "        with pdfplumber.open(pdf_path) as pdf, open(output_md, \"w\", encoding=\"utf-8\") as f:\n",
    "            for page_num, page in enumerate(pdf.pages, 1):\n",
    "                tables = page.extract_tables()\n",
    "                print(f\"Page {page_num}: {len(tables)} tables détectées\")\n",
    "                for i, table in enumerate(tables, 1):\n",
    "                    if not table or not table[0]:\n",
    "                        continue  \n",
    "                    md = \"\"\n",
    "                    md += \"| \" + \" | \".join(cell if cell is not None else \"\" for cell in table[0]) + \" |\\n\"\n",
    "                    md += \"| \" + \" | \".join([\"---\"] * len(table[0])) + \" |\\n\"\n",
    "                    for row in table[1:]:\n",
    "                        md += \"| \" + \" | \".join(cell if cell else \"\" for cell in row) + \" |\\n\"\n",
    "                    md += \"\\n\\n\" \n",
    "                    f.write(md)\n",
    "\n",
    "    pdf_tables_to_markdown(input_file, output_file)\n",
    "\n",
    "\n",
    "\n",
    "    # Extraction des tableaux à l'aide de la plateforme de LLM\n",
    "\n",
    "    input_file = f\"{nom_fichier}.md\"\n",
    "    output_file = f\"{nom_fichier}.txt\" \n",
    "\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        markdown_content = f.read()\n",
    "\n",
    "\n",
    "    prompt_LLM = f\"\"\"This is a Markdown file. Extract only the tables and give them back to me on a readable\n",
    "    .csv format. Don't comment and don't repharse. Above all else, dont add information from outside the Markdown\n",
    "    file. Let the tables how they are in the Markdown, do not mix them. When there is a line feed, it changes tables, so do it. There are always tables.\n",
    "    Often (but not always) a table starts with 'from' 'to'; Markdown : {markdown_content}\"\"\" #Transit Times'\n",
    "    safe_prompt_LLM = shlex.quote(prompt_LLM)\n",
    "\n",
    "    url = \"http://ollama-sam.inria.fr/api/generate\"\n",
    "    data = {'model': 'mistral:7b', 'prompt': safe_prompt_LLM}\n",
    "    auth = ('Bob', 'hiccup')  # HTTP Basic Auth\n",
    "\n",
    "    response = requests.post(url, json=data, auth=auth)\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as out_file:\n",
    "        out_file.write(response.text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Traitement du fichier .txt donné en réponse par le LLM\n",
    "\n",
    "    input_file = f\"{nom_fichier}.txt\"\n",
    "    response_file = f\"{nom_fichier}_response.txt\"\n",
    "    output_file = f\"{nom_fichier}_table.csv\"\n",
    "\n",
    "    responses = []\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as text_file:\n",
    "        for line in text_file:\n",
    "            try:\n",
    "                obj = json.loads(line.strip())\n",
    "                if \"response\" in obj:\n",
    "                    responses.append(obj[\"response\"])\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "    full_text = \"\".join(responses)\n",
    "    full_text = full_text.replace('\"\"\"', '').replace('\"', '')\n",
    "\n",
    "    with open(response_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(full_text)\n",
    "\n",
    "\n",
    "    # Conversion du fichier .txt amélioré en fichier .csv\n",
    "    lines = [line.strip() for line in full_text.strip().splitlines() if line.strip()]\n",
    "\n",
    "    with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        for line in lines:\n",
    "            writer.writerow(line.split(\",\"))\n",
    "\n",
    "    # Vérification que le model LLM n'invente pas des données et fais simplement de l'extraction de données\n",
    "    # Faire un test de vérification\n",
    "\n",
    "    input_file = f\"{nom_fichier}_response.txt\"\n",
    "    output_base = f\"{nom_fichier}_table\"\n",
    "\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Extraire contenu entre ```\n",
    "    match = re.search(r\"```(.*?)```\", content, re.DOTALL)\n",
    "    if not match:\n",
    "        raise ValueError(\"Bloc markdown ``` non trouvé dans le fichier de réponse\")\n",
    "\n",
    "    tables_text = match.group(1).strip()\n",
    "\n",
    "    lines = [line.strip() for line in tables_text.splitlines() if line.strip()]\n",
    "\n",
    "    # Trouver l'index où la deuxième table commence\n",
    "    split_index = None\n",
    "    prev_len = None\n",
    "    for i, line in enumerate(lines):\n",
    "        cols = line.split(\",\")\n",
    "        if prev_len is not None and len(cols) > prev_len:\n",
    "            split_index = i\n",
    "            break\n",
    "        prev_len = len(cols)\n",
    "\n",
    "    if split_index is None:\n",
    "        tables = [lines]\n",
    "    else:\n",
    "        tables = [lines[:split_index], lines[split_index:]]\n",
    "    if len(tables) > 1:\n",
    "        second_table = tables[1]\n",
    "        first_line_cols = second_table[0].split(\",\")\n",
    "        first_line_cols[0] = \"To\\nFrom\"\n",
    "        import io\n",
    "        output = io.StringIO()\n",
    "        writer = csv.writer(output, quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow(first_line_cols)\n",
    "        tables[1][0] = output.getvalue().strip() \n",
    "\n",
    "    # Écriture des tables dans des fichiers CSV\n",
    "    for i, table_lines in enumerate(tables, 1):\n",
    "        output_file = f\"{output_base}_{i}.csv\"\n",
    "        with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "            writer = csv.writer(csv_file, quoting=csv.QUOTE_MINIMAL)\n",
    "            for line in table_lines:\n",
    "                row = next(csv.reader([line]))\n",
    "                writer.writerow(row)\n",
    "        print(f\"Table {i} saved in {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
